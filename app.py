import streamlit as st
import numpy as np
import torch
import os
import imageio_ffmpeg
from utils import extract_audio, transcribe_audio, summarize_text, clip_video, match_summary_to_segments
import moviepy.editor as mp

os.environ["TOKENIZERS_PARALLELISM"] = "false"
st.set_page_config(layout="centered")

st.sidebar.write("âœ… Numpy:", np.__version__)
st.sidebar.write("âœ… Torch:", torch.__version__)
st.sidebar.write("âœ… Whisper loaded")

st.title("ğŸ¥ Video Summary from Long Lectures")

video_file = st.file_uploader("Upload a lecture video", type=["mp4", "mov", "avi", "webm"])

if video_file:
    with open("uploaded_video.mp4", "wb") as f:
        f.write(video_file.read())
    st.video("uploaded_video.mp4")

    if st.button("ğŸ”Š Extract & Transcribe Audio"):
        st.info("Processing audio and transcription...")
        audio_path = extract_audio("uploaded_video.mp4")
        transcript, segments = transcribe_audio(audio_path)
        st.session_state['transcript'] = transcript
        st.session_state['segments'] = segments
        st.success("Transcription complete!")
        st.text_area("ğŸ“ Transcript", transcript, height=300)

    if "transcript" in st.session_state:
        if st.button("ğŸ§  Generate Summary"):
            summary = summarize_text(st.session_state['transcript'])
            st.session_state['summary'] = summary
            st.success("Summary generated!")
            st.text_area("ğŸ§¾ Summary", summary, height=200)

    if 'transcript' in st.session_state:
        st.download_button("ğŸ“¥ Download Transcript", st.session_state['transcript'], file_name="transcript.txt")

    if 'summary' in st.session_state:
        st.download_button("ğŸ“¥ Download Summary", st.session_state['summary'], file_name="summary.txt")

        st.header("ğŸ¯ Extract a Short Video Clip")
        col1, col2 = st.columns(2)
        with col1:
            start_time = st.number_input("Start time (seconds)", min_value=0)
        with col2:
            end_time = st.number_input("End time (seconds)", min_value=1)

        if st.button("âœ‚ï¸ Create Clip"):
            if start_time < end_time:
                clip_path = clip_video("uploaded_video.mp4", start_time, end_time)
                st.video(clip_path)
                st.success("Clip created successfully!")
            else:
                st.error("Start time must be less than end time.")

    if "summary" in st.session_state and "segments" in st.session_state:
        if st.button("ğŸ Generate Final Summary Clip"):
            matched_segments = match_summary_to_segments(st.session_state["summary"], st.session_state["segments"])
            if matched_segments:
                final_clip = None
                for start, end in matched_segments:
                    part = mp.VideoFileClip("uploaded_video.mp4").subclip(start, end)
                    final_clip = part if final_clip is None else mp.concatenate_videoclips([final_clip, part])
                final_path = "summary_clip.mp4"
                final_clip.write_videofile(final_path)
                st.video(final_path)
                st.success("âœ… Final summary clip created!")
            else:
                st.warning("âš ï¸ No matching segments found in summary.")